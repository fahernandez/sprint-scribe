{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "668e5502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API Key:\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangChain API Key:\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"Sprint Scribe - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Cohere API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89112682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../data/TF-Task.csv', 'row': 0, 'Issue key': 'TDF-156', 'Parent key': 'TDF-1', 'Parent summary': 'Initiation:Discovery'}, page_content=\"Summary: Tailor the customer questionnaire\\nDescription: Using information obtained from the GTM and CSA teams, as well as from the client kick-off meeting, tailor the questionnaire that will be used in the client workshops.\\n\\nThe goals are:\\n\\n# Address relevant questions with answers that we already have\\n# Reduce the questionnaire to the relevant questions that we don’t already have answers for\\n\\nThe outcome will be a focused questionnaire that can be used in the discovery workshops when we can confirm the information we already heard, and ask only the relevant remaining questions.  This will let the client know that we’ve been listening to them since the beginning, that the different teams in Infostrux are talking to one another and that we respect the client’s time by not repeating the same set of questions.\\n\\n(TIP:  invite the CSA team member to help tailor the questionnaire so that they can supply the info they have)\\n\\nUse the following template as the base for your questionnaire:\\n\\n[https://docs.google.com/spreadsheets/d/1zPzMetyBDuwizTgMRENQCP7WbXGKLpviUVRekpksLDY/edit?usp=sharing|https://docs.google.com/spreadsheets/d/1zPzMetyBDuwizTgMRENQCP7WbXGKLpviUVRekpksLDY/edit?usp=sharing|smart-link] \\n\\nComplete the information you already know, avoid unnecessary queries for the customer for domains that are not relevant to the engagement, and refrain from sharing your screen or the document in its entirety to prevent overwhelming the customer.\\n\\n*Acceptance Criteria:*\\n\\n* Create a copy of the questionnaire and store it in the client's Google Drive folder\\n* Fill in all details that we can before the client discovery calls so that we know what to fill in during these calls (the missing details)\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=f\"../data/TF-Task.csv\",\n",
    "    metadata_columns=[\n",
    "        \"Issue key\",\n",
    "        \"Parent key\",\n",
    "        \"Parent summary\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "jira_tickets = loader.load()\n",
    "jira_tickets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed5c18",
   "metadata": {},
   "source": [
    "# Sintatic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fa8c5e",
   "metadata": {},
   "source": [
    "### TODO\n",
    "1. Use the EPIC information to create cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a01e4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d0340b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 0, relationships: 0)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6f31b8a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 140, relationships: 0)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.graph import Node, NodeType\n",
    "\n",
    "### NOTICE: We're using a subset of the data for this example - this is to keep costs/time down.\n",
    "for ticket in jira_tickets:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\n",
    "                \"page_content\": ticket.page_content,\n",
    "                \"document_metadata\": ticket.metadata,\n",
    "            },\n",
    "        )\n",
    "    )\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9875a8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f24500f7bf44e78ad7b2c45a21305dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying SummaryExtractor:   0%|          | 0/95 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd963aab3e9c4724baeff8c0f2b7e802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying CustomNodeFilter:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Node 919433d5-5083-4024-9bcd-ed912ad93b1b does not have a summary. Skipping filtering.\n",
      "Node 607f1b7f-d15c-491b-b479-24c74d579b2e does not have a summary. Skipping filtering.\n",
      "Node 0d2b149d-7f9f-4d3c-8448-673f54d584e4 does not have a summary. Skipping filtering.\n",
      "Node 9e162d88-6d28-4286-b7cb-74b5f0984906 does not have a summary. Skipping filtering.\n",
      "Node 187629f5-9152-4f41-8277-c3fe99402495 does not have a summary. Skipping filtering.\n",
      "Node ebaeaed9-cf09-4795-84a8-8cc84ca40498 does not have a summary. Skipping filtering.\n",
      "Node e1974d52-60f5-4f47-a3a7-8ebfaeafa10f does not have a summary. Skipping filtering.\n",
      "Node 532ca24c-bd37-4a81-a685-b8c106dabddd does not have a summary. Skipping filtering.\n",
      "Node c41b1dff-64b8-48f5-9ebc-85c0a86d6af1 does not have a summary. Skipping filtering.\n",
      "Node 68126742-58e8-4a8f-b36e-c1a38af24c08 does not have a summary. Skipping filtering.\n",
      "Node 0b9149a9-a888-428f-88f4-4fd407288384 does not have a summary. Skipping filtering.\n",
      "Node 190bbef0-d233-46e4-b6ea-52c19a5a47d8 does not have a summary. Skipping filtering.\n",
      "Node 38c574d5-dd64-4b27-afbd-c474e4262bb0 does not have a summary. Skipping filtering.\n",
      "Node deb1c98d-20ad-4b9f-b513-56c34dcfd14c does not have a summary. Skipping filtering.\n",
      "Node 8e5db5fa-e786-41c4-ab43-a9029c093937 does not have a summary. Skipping filtering.\n",
      "Node d377dc79-497d-483c-9fc2-810c21348bcf does not have a summary. Skipping filtering.\n",
      "Node 33356374-f0cd-401c-af3d-92469edca1bb does not have a summary. Skipping filtering.\n",
      "Node 30cc9e6f-1b78-400d-ac26-35d9c51fad8e does not have a summary. Skipping filtering.\n",
      "Node df379f22-c139-4cef-83fd-f240a591a5a0 does not have a summary. Skipping filtering.\n",
      "Node be2ce023-ee98-47b6-86e4-aa54b33abed7 does not have a summary. Skipping filtering.\n",
      "Node 9039d8ec-b710-4004-b682-ac891b0c4618 does not have a summary. Skipping filtering.\n",
      "Node 771403fa-e83d-41a8-9127-fe2b5526bb7d does not have a summary. Skipping filtering.\n",
      "Node 7622a385-7160-49c5-b422-b6fd9d2a39ae does not have a summary. Skipping filtering.\n",
      "Node c634396a-08cc-4440-aceb-8b33c057e51d does not have a summary. Skipping filtering.\n",
      "Node a88c4a92-2251-4b3c-99da-c8b2e793d9ad does not have a summary. Skipping filtering.\n",
      "Node b8c0f09d-83c0-4188-8a71-c47286f36b19 does not have a summary. Skipping filtering.\n",
      "Node 12b3fd15-8a41-4909-af21-96fe8513cf34 does not have a summary. Skipping filtering.\n",
      "Node d369fc81-48b8-45a8-ae41-055721708c10 does not have a summary. Skipping filtering.\n",
      "Node 3216e023-16d9-4a71-bb6c-256c4b780a9c does not have a summary. Skipping filtering.\n",
      "Node ce461c48-4738-449f-be2a-7a996cecf563 does not have a summary. Skipping filtering.\n",
      "Node 37ba3a86-217f-4627-9b3f-c8bca9f4b524 does not have a summary. Skipping filtering.\n",
      "Node 528e24dc-4042-44d4-b1ad-1df49f7d1bfe does not have a summary. Skipping filtering.\n",
      "Node 89c70b9a-0ea7-4576-968b-21d641356f1a does not have a summary. Skipping filtering.\n",
      "Node 87bad560-03f2-4d68-8903-04d2878cab93 does not have a summary. Skipping filtering.\n",
      "Node 387424fe-537f-417f-8c60-da40034d887d does not have a summary. Skipping filtering.\n",
      "Node 69a4e997-3e83-4583-b2a3-a33c88705fe5 does not have a summary. Skipping filtering.\n",
      "Node fd4b5ce9-ebb1-4358-8513-7091f111e7c6 does not have a summary. Skipping filtering.\n",
      "Node b64a8894-314b-4850-b951-f8c620fd35a8 does not have a summary. Skipping filtering.\n",
      "Node 47b87889-853b-4f58-8bbe-d9620b6c7fb0 does not have a summary. Skipping filtering.\n",
      "Node 868164d9-851f-4a3d-ace4-4fc8836c3563 does not have a summary. Skipping filtering.\n",
      "Node 05848818-76ab-42fc-aeb6-4a3e1270c5c6 does not have a summary. Skipping filtering.\n",
      "Node 64fd1322-3cc2-4043-9a92-8252cef14459 does not have a summary. Skipping filtering.\n",
      "Node 15b80b37-8396-4c19-a01b-794b91751a45 does not have a summary. Skipping filtering.\n",
      "Node 2789ad43-b93f-4740-8c23-64bc0c6b1889 does not have a summary. Skipping filtering.\n",
      "Node f871985e-e3f0-43cb-a031-771887ba961e does not have a summary. Skipping filtering.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4276791a856a4f96a17f105c15b235e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934e44571b2f41cfab5035852ee7fe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying OverlapScoreBuilder:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 140, relationships: 482)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "default_transforms = default_transforms(\n",
    "    documents=jira_tickets, llm=transformer_llm, embedding_model=embedding_model\n",
    ")\n",
    "apply_transforms(kg, default_transforms)\n",
    "kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1cf3aaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes: 140, relationships: 482)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kg.save(\"loan_data_kg.json\")\n",
    "loan_data_kg = KnowledgeGraph.load(\"loan_data_kg.json\")\n",
    "loan_data_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "13e87124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm, embedding_model=embedding_model, knowledge_graph=loan_data_kg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3c083341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.synthesizers import (\n",
    "    default_query_distribution,\n",
    "    SingleHopSpecificQuerySynthesizer,\n",
    "    MultiHopAbstractQuerySynthesizer,\n",
    "    MultiHopSpecificQuerySynthesizer,\n",
    ")\n",
    "\n",
    "query_distribution = [\n",
    "    (SingleHopSpecificQuerySynthesizer(llm=generator_llm), 1.0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997b1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ea3629ef184c76adeab152b55c6c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Scenarios:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd2c3aa64f3e4080a1280ab64c1a7d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Samples:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How should the CSA team contribute to tailorin...</td>\n",
       "      <td>[Summary: Tailor the customer questionnaire\\nD...</td>\n",
       "      <td>The CSA team member should be invited to help ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wher can I find the atlassian documments relat...</td>\n",
       "      <td>[Summary: Infrastructure Workshop\\nDescription...</td>\n",
       "      <td>Example questions which can be used in some ca...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>where i find Infostrux folder?</td>\n",
       "      <td>[Summary: Data Workshop\\nDescription: As a dev...</td>\n",
       "      <td>\"Customers/&lt;customer&gt;/Infostrux - &lt;customer&gt; S...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how i use terraform-snowflake-rbac-infra for m...</td>\n",
       "      <td>[Summary: CI/CD Tunnels (Optional)\\nDescriptio...</td>\n",
       "      <td>You can look at the example from the RBAC pipe...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How is RBAC integrated into the CI/CD pipeline...</td>\n",
       "      <td>[Summary: CI/CD Connectors (Optional)\\nDescrip...</td>\n",
       "      <td>RBAC is integrated into the CI/CD pipeline for...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How can Terraform be used to set up Fivetran S...</td>\n",
       "      <td>[Summary: Fivetran:Terraform SSH Tunnels (Opti...</td>\n",
       "      <td>Terraform can be used to implement Fivetran SS...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Whaat is a Terrafom providr and howw can it be...</td>\n",
       "      <td>[Summary: Fivetran:Terraform Destinations, Con...</td>\n",
       "      <td>A Terraform provider for Fivetran allows us to...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What are the requirements and considerations f...</td>\n",
       "      <td>[Summary: Communicate Requirements\\nDescriptio...</td>\n",
       "      <td>For SQL Server implementations, either CDC (Ch...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Howw do I set up a Fivetran destinashun in Sno...</td>\n",
       "      <td>[Summary: Fivetran Destination\\nDescription: A...</td>\n",
       "      <td>To set up a Fivetran destination in Snowflake,...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How we use Airbyte if not do Fivetran setup?</td>\n",
       "      <td>[Summary: Fivetran Account\\nDescription: As a ...</td>\n",
       "      <td>Depending on sources, Fivetran setup can be sk...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Howw do I set up Snoflake in Airbyte?</td>\n",
       "      <td>[Summary: Airbyte Installation and Config\\nDes...</td>\n",
       "      <td>Snowflake is configured as a destination in Ai...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How is Terraform utilized in deploying the Air...</td>\n",
       "      <td>[Summary: Airbyte EC2\\nDescription: As a devel...</td>\n",
       "      <td>The Airbyte EC2 instance is deployed to a cust...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Whaat is the role of the Engagment Manager dur...</td>\n",
       "      <td>[Summary: Engagement Setup\\nDescription: *Enga...</td>\n",
       "      <td>The Engagement Manager begins setting up the e...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What steps are involved in staffing a new clie...</td>\n",
       "      <td>[Summary: Staff the Engagement\\nDescription: *...</td>\n",
       "      <td>Professional Services leadership collaborates ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the significance of the Client in the ...</td>\n",
       "      <td>[Summary: Client Kickoff\\nDescription: *Client...</td>\n",
       "      <td>In the Client Kickoff process, the Client part...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>what client info need for kickoff?</td>\n",
       "      <td>[Summary: Internal Handoff\\nDescription: The s...</td>\n",
       "      <td>The sales/presales team needs to transfer Clie...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Could you please provide a comprehensive expla...</td>\n",
       "      <td>[Summary: Delivery Team to fill out Marketing ...</td>\n",
       "      <td>The Delivery Team is responsible for filling o...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Where can I find detailed information about th...</td>\n",
       "      <td>[Summary: Last Week\\nDescription: *Acceptance ...</td>\n",
       "      <td>Detailed information about the close-out proce...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What is Infostrux's role in project wrap-up pr...</td>\n",
       "      <td>[Summary: T minus 1 week\\nDescription: *Accept...</td>\n",
       "      <td>Infostrux is responsible for internal communic...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>wat hapens at T minus 2 week?</td>\n",
       "      <td>[Summary: T minus 2 week\\nDescription: *Accept...</td>\n",
       "      <td>At T minus 2 week, status is reported to all s...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>As a Data Quality Project Manager, how should ...</td>\n",
       "      <td>[Summary: T minus 3 weeks\\nDescription: *Accep...</td>\n",
       "      <td>During the final three weeks of the project, t...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What steps should be taken to ensure that the ...</td>\n",
       "      <td>[Summary: T minus 4 weeks\\nDescription: *Accep...</td>\n",
       "      <td>According to the documented acceptance criteri...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>how get AWS docs signed?</td>\n",
       "      <td>[Summary: [if applicable] get AWS and/or Snowf...</td>\n",
       "      <td>get AWS and/or Snowflake funding documents sig...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What responsibilities does a pod manager have ...</td>\n",
       "      <td>[Summary: send a reminder message to tech lead...</td>\n",
       "      <td>A pod manager is responsible for cleaning up t...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>who is GTM in this meeting?</td>\n",
       "      <td>[Summary: schedule engagement retrospective wi...</td>\n",
       "      <td>GTM is listed as one of the participants to be...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>how we remove client users from jira?</td>\n",
       "      <td>[Summary: remove client users from jira\\nDescr...</td>\n",
       "      <td>Summary say to remove client users from jira.</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>What Infostrux do for project, when finish, wh...</td>\n",
       "      <td>[Summary: inform all stakeholders of impending...</td>\n",
       "      <td>Infostrux team expects to complete the current...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>where KT Template link go?</td>\n",
       "      <td>[Summary: Hand-off\\nDescription: As a client, ...</td>\n",
       "      <td>KT Template link go to https://infostrux.atlas...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is demonstrated regarding the CI/CD proce...</td>\n",
       "      <td>[Summary: Demo\\nDescription: As a client, I wa...</td>\n",
       "      <td>The client meeting includes a demonstration of...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What are the requirements and objectives for e...</td>\n",
       "      <td>[Summary: SnowPipe:QA\\nDescription: As a user,...</td>\n",
       "      <td>According to the SnowPipe:QA summary, the obje...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What is the role of Snowpipe in the CI/CD proc...</td>\n",
       "      <td>[Summary: SnowPipe:CI/CD\\nDescription: As a de...</td>\n",
       "      <td>Snowpipe is automatically built, tested, and d...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Cud yu pleese explane wut SnowPipe is and how ...</td>\n",
       "      <td>[Summary: SnowPipe:Code\\nDescription: As a cus...</td>\n",
       "      <td>SnowPipe is used to load semi-structured data ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           user_input  \\\n",
       "0   How should the CSA team contribute to tailorin...   \n",
       "1   Wher can I find the atlassian documments relat...   \n",
       "2                      where i find Infostrux folder?   \n",
       "3   how i use terraform-snowflake-rbac-infra for m...   \n",
       "4   How is RBAC integrated into the CI/CD pipeline...   \n",
       "5   How can Terraform be used to set up Fivetran S...   \n",
       "6   Whaat is a Terrafom providr and howw can it be...   \n",
       "7   What are the requirements and considerations f...   \n",
       "8   Howw do I set up a Fivetran destinashun in Sno...   \n",
       "9        How we use Airbyte if not do Fivetran setup?   \n",
       "10              Howw do I set up Snoflake in Airbyte?   \n",
       "11  How is Terraform utilized in deploying the Air...   \n",
       "12  Whaat is the role of the Engagment Manager dur...   \n",
       "13  What steps are involved in staffing a new clie...   \n",
       "14  What is the significance of the Client in the ...   \n",
       "15                 what client info need for kickoff?   \n",
       "16  Could you please provide a comprehensive expla...   \n",
       "17  Where can I find detailed information about th...   \n",
       "18  What is Infostrux's role in project wrap-up pr...   \n",
       "19                      wat hapens at T minus 2 week?   \n",
       "20  As a Data Quality Project Manager, how should ...   \n",
       "21  What steps should be taken to ensure that the ...   \n",
       "22                           how get AWS docs signed?   \n",
       "23  What responsibilities does a pod manager have ...   \n",
       "24                        who is GTM in this meeting?   \n",
       "25              how we remove client users from jira?   \n",
       "26  What Infostrux do for project, when finish, wh...   \n",
       "27                         where KT Template link go?   \n",
       "28  What is demonstrated regarding the CI/CD proce...   \n",
       "29  What are the requirements and objectives for e...   \n",
       "30  What is the role of Snowpipe in the CI/CD proc...   \n",
       "31  Cud yu pleese explane wut SnowPipe is and how ...   \n",
       "\n",
       "                                   reference_contexts  \\\n",
       "0   [Summary: Tailor the customer questionnaire\\nD...   \n",
       "1   [Summary: Infrastructure Workshop\\nDescription...   \n",
       "2   [Summary: Data Workshop\\nDescription: As a dev...   \n",
       "3   [Summary: CI/CD Tunnels (Optional)\\nDescriptio...   \n",
       "4   [Summary: CI/CD Connectors (Optional)\\nDescrip...   \n",
       "5   [Summary: Fivetran:Terraform SSH Tunnels (Opti...   \n",
       "6   [Summary: Fivetran:Terraform Destinations, Con...   \n",
       "7   [Summary: Communicate Requirements\\nDescriptio...   \n",
       "8   [Summary: Fivetran Destination\\nDescription: A...   \n",
       "9   [Summary: Fivetran Account\\nDescription: As a ...   \n",
       "10  [Summary: Airbyte Installation and Config\\nDes...   \n",
       "11  [Summary: Airbyte EC2\\nDescription: As a devel...   \n",
       "12  [Summary: Engagement Setup\\nDescription: *Enga...   \n",
       "13  [Summary: Staff the Engagement\\nDescription: *...   \n",
       "14  [Summary: Client Kickoff\\nDescription: *Client...   \n",
       "15  [Summary: Internal Handoff\\nDescription: The s...   \n",
       "16  [Summary: Delivery Team to fill out Marketing ...   \n",
       "17  [Summary: Last Week\\nDescription: *Acceptance ...   \n",
       "18  [Summary: T minus 1 week\\nDescription: *Accept...   \n",
       "19  [Summary: T minus 2 week\\nDescription: *Accept...   \n",
       "20  [Summary: T minus 3 weeks\\nDescription: *Accep...   \n",
       "21  [Summary: T minus 4 weeks\\nDescription: *Accep...   \n",
       "22  [Summary: [if applicable] get AWS and/or Snowf...   \n",
       "23  [Summary: send a reminder message to tech lead...   \n",
       "24  [Summary: schedule engagement retrospective wi...   \n",
       "25  [Summary: remove client users from jira\\nDescr...   \n",
       "26  [Summary: inform all stakeholders of impending...   \n",
       "27  [Summary: Hand-off\\nDescription: As a client, ...   \n",
       "28  [Summary: Demo\\nDescription: As a client, I wa...   \n",
       "29  [Summary: SnowPipe:QA\\nDescription: As a user,...   \n",
       "30  [Summary: SnowPipe:CI/CD\\nDescription: As a de...   \n",
       "31  [Summary: SnowPipe:Code\\nDescription: As a cus...   \n",
       "\n",
       "                                            reference  \\\n",
       "0   The CSA team member should be invited to help ...   \n",
       "1   Example questions which can be used in some ca...   \n",
       "2   \"Customers/<customer>/Infostrux - <customer> S...   \n",
       "3   You can look at the example from the RBAC pipe...   \n",
       "4   RBAC is integrated into the CI/CD pipeline for...   \n",
       "5   Terraform can be used to implement Fivetran SS...   \n",
       "6   A Terraform provider for Fivetran allows us to...   \n",
       "7   For SQL Server implementations, either CDC (Ch...   \n",
       "8   To set up a Fivetran destination in Snowflake,...   \n",
       "9   Depending on sources, Fivetran setup can be sk...   \n",
       "10  Snowflake is configured as a destination in Ai...   \n",
       "11  The Airbyte EC2 instance is deployed to a cust...   \n",
       "12  The Engagement Manager begins setting up the e...   \n",
       "13  Professional Services leadership collaborates ...   \n",
       "14  In the Client Kickoff process, the Client part...   \n",
       "15  The sales/presales team needs to transfer Clie...   \n",
       "16  The Delivery Team is responsible for filling o...   \n",
       "17  Detailed information about the close-out proce...   \n",
       "18  Infostrux is responsible for internal communic...   \n",
       "19  At T minus 2 week, status is reported to all s...   \n",
       "20  During the final three weeks of the project, t...   \n",
       "21  According to the documented acceptance criteri...   \n",
       "22  get AWS and/or Snowflake funding documents sig...   \n",
       "23  A pod manager is responsible for cleaning up t...   \n",
       "24  GTM is listed as one of the participants to be...   \n",
       "25      Summary say to remove client users from jira.   \n",
       "26  Infostrux team expects to complete the current...   \n",
       "27  KT Template link go to https://infostrux.atlas...   \n",
       "28  The client meeting includes a demonstration of...   \n",
       "29  According to the SnowPipe:QA summary, the obje...   \n",
       "30  Snowpipe is automatically built, tested, and d...   \n",
       "31  SnowPipe is used to load semi-structured data ...   \n",
       "\n",
       "                        synthesizer_name  \n",
       "0   single_hop_specifc_query_synthesizer  \n",
       "1   single_hop_specifc_query_synthesizer  \n",
       "2   single_hop_specifc_query_synthesizer  \n",
       "3   single_hop_specifc_query_synthesizer  \n",
       "4   single_hop_specifc_query_synthesizer  \n",
       "5   single_hop_specifc_query_synthesizer  \n",
       "6   single_hop_specifc_query_synthesizer  \n",
       "7   single_hop_specifc_query_synthesizer  \n",
       "8   single_hop_specifc_query_synthesizer  \n",
       "9   single_hop_specifc_query_synthesizer  \n",
       "10  single_hop_specifc_query_synthesizer  \n",
       "11  single_hop_specifc_query_synthesizer  \n",
       "12  single_hop_specifc_query_synthesizer  \n",
       "13  single_hop_specifc_query_synthesizer  \n",
       "14  single_hop_specifc_query_synthesizer  \n",
       "15  single_hop_specifc_query_synthesizer  \n",
       "16  single_hop_specifc_query_synthesizer  \n",
       "17  single_hop_specifc_query_synthesizer  \n",
       "18  single_hop_specifc_query_synthesizer  \n",
       "19  single_hop_specifc_query_synthesizer  \n",
       "20  single_hop_specifc_query_synthesizer  \n",
       "21  single_hop_specifc_query_synthesizer  \n",
       "22  single_hop_specifc_query_synthesizer  \n",
       "23  single_hop_specifc_query_synthesizer  \n",
       "24  single_hop_specifc_query_synthesizer  \n",
       "25  single_hop_specifc_query_synthesizer  \n",
       "26  single_hop_specifc_query_synthesizer  \n",
       "27  single_hop_specifc_query_synthesizer  \n",
       "28  single_hop_specifc_query_synthesizer  \n",
       "29  single_hop_specifc_query_synthesizer  \n",
       "30  single_hop_specifc_query_synthesizer  \n",
       "31  single_hop_specifc_query_synthesizer  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset = generator.generate(testset_size=120, query_distribution=query_distribution)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb6f07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f10a02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"Sprint Scribe v1.0\"\n",
    "\n",
    "langsmith_dataset = client.create_dataset(\n",
    "    dataset_name=dataset_name, description=\"Sprint Scribe v1.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14dc9237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_row in testset.to_pandas().iterrows():\n",
    "    client.create_example(\n",
    "        inputs={\"question\": data_row[1][\"user_input\"]},\n",
    "        outputs={\"answer\": data_row[1][\"reference\"]},\n",
    "        metadata={\"context\": data_row[1][\"reference_contexts\"]},\n",
    "        dataset_id=langsmith_dataset.id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263b4d9",
   "metadata": {},
   "source": [
    "# Evaluating retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce0f0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_loaders.langsmith import LangSmithDatasetChatLoader\n",
    "\n",
    "# Load the dataset from Langchain by name\n",
    "dataset = client.read_dataset(dataset_name=\"Sprint Scribe v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ca384d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference</th>\n",
       "      <th>reference_contexts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What responsibilities does a pod manager have ...</td>\n",
       "      <td>A pod manager is responsible for cleaning up t...</td>\n",
       "      <td>[Summary: send a reminder message to tech lead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What steps should be taken to ensure that the ...</td>\n",
       "      <td>According to the documented acceptance criteri...</td>\n",
       "      <td>[Summary: T minus 4 weeks\\nDescription: *Accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a Data Quality Project Manager, how should ...</td>\n",
       "      <td>During the final three weeks of the project, t...</td>\n",
       "      <td>[Summary: T minus 3 weeks\\nDescription: *Accep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wat hapens at T minus 2 week?</td>\n",
       "      <td>At T minus 2 week, status is reported to all s...</td>\n",
       "      <td>[Summary: T minus 2 week\\nDescription: *Accept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is Infostrux's role in project wrap-up pr...</td>\n",
       "      <td>Infostrux is responsible for internal communic...</td>\n",
       "      <td>[Summary: T minus 1 week\\nDescription: *Accept...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  What responsibilities does a pod manager have ...   \n",
       "1  What steps should be taken to ensure that the ...   \n",
       "2  As a Data Quality Project Manager, how should ...   \n",
       "3                      wat hapens at T minus 2 week?   \n",
       "4  What is Infostrux's role in project wrap-up pr...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  A pod manager is responsible for cleaning up t...   \n",
       "1  According to the documented acceptance criteri...   \n",
       "2  During the final three weeks of the project, t...   \n",
       "3  At T minus 2 week, status is reported to all s...   \n",
       "4  Infostrux is responsible for internal communic...   \n",
       "\n",
       "                                  reference_contexts  \n",
       "0  [Summary: send a reminder message to tech lead...  \n",
       "1  [Summary: T minus 4 weeks\\nDescription: *Accep...  \n",
       "2  [Summary: T minus 3 weeks\\nDescription: *Accep...  \n",
       "3  [Summary: T minus 2 week\\nDescription: *Accept...  \n",
       "4  [Summary: T minus 1 week\\nDescription: *Accept...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset examples from LangSmith\n",
    "examples = list(client.list_examples(dataset_id=dataset.id))\n",
    "import pandas as pd\n",
    "\n",
    "# Transform the list of Example objects to a pandas DataFrame\n",
    "examples_df = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"user_input\": ex.inputs[\"question\"],\n",
    "            \"reference\": ex.outputs[\"answer\"],\n",
    "            \"reference_contexts\": ex.metadata[\"context\"],\n",
    "        }\n",
    "        for ex in examples\n",
    "    ]\n",
    ")\n",
    "examples_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ccf9a7",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194fe056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4.1-mini\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6ea1f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "naive_retrieval_dataset = copy.deepcopy(examples_df)\n",
    "bm25_retrieval_dataset = copy.deepcopy(examples_df)\n",
    "multi_query_retrieval_dataset = copy.deepcopy(examples_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6de53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\\\n",
    "You are a helpful and kind assistant. Use the context provided below to answer the question.\n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f606ae32",
   "metadata": {},
   "source": [
    "# Naive Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectorstore = Qdrant.from_documents(\n",
    "    jira_tickets,\n",
    "    embeddings,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"LoanComplaints\",\n",
    ")\n",
    "naive_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "naive_retrieval_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | naive_retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "588f99f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retrieval_dataset[\"response\"] = \"\"\n",
    "naive_retrieval_dataset[\"retrieved_contexts\"] = [\n",
    "    [] for _ in range(len(naive_retrieval_dataset))\n",
    "]\n",
    "\n",
    "for k, v in naive_retrieval_dataset.iterrows():\n",
    "    response = naive_retrieval_chain.invoke({\"question\": v.user_input})\n",
    "    naive_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
    "    naive_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71d9dc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e74e049544448ea7b809d3a8d5752e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[50]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception raised in Job[53]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception raised in Job[29]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception raised in Job[65]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception raised in Job[17]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8889, 'faithfulness': 0.8564, 'factual_correctness': 0.4935, 'answer_relevancy': 0.9127, 'context_entity_recall': 0.5356, 'noise_sensitivity_relevant': 0.2317}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    LLMContextRecall,\n",
    "    Faithfulness,\n",
    "    FactualCorrectness,\n",
    "    ResponseRelevancy,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    ")\n",
    "from ragas import evaluate, RunConfig\n",
    "from ragas import EvaluationDataset\n",
    "\n",
    "custom_run_config = RunConfig(timeout=360)\n",
    "\n",
    "naive_retrieval_result = evaluate(\n",
    "    dataset=EvaluationDataset.from_pandas(naive_retrieval_dataset),\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=RunConfig(timeout=360),\n",
    ")\n",
    "naive_retrieval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cef4f5",
   "metadata": {},
   "source": [
    "# MB25 Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63751ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(\n",
    "    jira_tickets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf8c730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retrieval_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | bm25_retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecf7839e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retrieval_dataset[\"response\"] = \"\"\n",
    "bm25_retrieval_dataset[\"retrieved_contexts\"] = [\n",
    "    [] for _ in range(len(bm25_retrieval_dataset))\n",
    "]\n",
    "\n",
    "for k, v in bm25_retrieval_dataset.iterrows():\n",
    "    response = bm25_retrieval_chain.invoke({\"question\": v.user_input})\n",
    "    bm25_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
    "    bm25_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "739f611b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f228660ea34a88aa01313112469835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.6296, 'faithfulness': 0.6716, 'factual_correctness': 0.4572, 'answer_relevancy': 0.7520, 'context_entity_recall': 0.4301, 'noise_sensitivity_relevant': 0.1710}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retrieval_result = evaluate(\n",
    "    dataset=EvaluationDataset.from_pandas(bm25_retrieval_dataset),\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=RunConfig(timeout=360),\n",
    ")\n",
    "bm25_retrieval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93c148",
   "metadata": {},
   "source": [
    "# Multi-query retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6663b63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "\n",
    "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=naive_retriever, llm=chat_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eb18818",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retrieval_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | multi_query_retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aa80b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_query_retrieval_dataset[\"response\"] = \"\"\n",
    "multi_query_retrieval_dataset[\"retrieved_contexts\"] = [\n",
    "    [] for _ in range(len(multi_query_retrieval_dataset))\n",
    "]\n",
    "\n",
    "for k, v in multi_query_retrieval_dataset.iterrows():\n",
    "    response = multi_query_retrieval_chain.invoke({\"question\": v.user_input})\n",
    "    multi_query_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
    "    multi_query_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb41894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ab070e2ce748c0a95978be5b4b32b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[17]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 1.0000, 'faithfulness': 0.8607, 'factual_correctness': 0.4522, 'answer_relevancy': 0.9662, 'context_entity_recall': 0.4989, 'noise_sensitivity_relevant': 0.2659}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_retrieval_result = evaluate(\n",
    "    dataset=EvaluationDataset.from_pandas(multi_query_retrieval_dataset),\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=RunConfig(timeout=360),\n",
    ")\n",
    "multi_query_retrieval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d02b3",
   "metadata": {},
   "source": [
    "# Ensemble retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6331165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "ensemble_retrieval_dataset = copy.deepcopy(examples_df)\n",
    "\n",
    "retriever_list = [\n",
    "    bm25_retriever,\n",
    "    naive_retriever,\n",
    "    multi_query_retriever,\n",
    "]\n",
    "equal_weighting = [1 / len(retriever_list)] * len(retriever_list)\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(\n",
    "    retrievers=retriever_list, weights=equal_weighting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bca26f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retrieval_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | ensemble_retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "05060a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_retrieval_dataset[\"response\"] = \"\"\n",
    "ensemble_retrieval_dataset[\"retrieved_contexts\"] = [\n",
    "    [] for _ in range(len(ensemble_retrieval_dataset))\n",
    "]\n",
    "\n",
    "for k, v in ensemble_retrieval_dataset.iterrows():\n",
    "    response = ensemble_retrieval_chain.invoke({\"question\": v.user_input})\n",
    "    ensemble_retrieval_dataset.at[k, \"response\"] = response[\"response\"].content\n",
    "    ensemble_retrieval_dataset.at[k, \"retrieved_contexts\"] = [\n",
    "        context.page_content for context in response[\"context\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30dc3cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e61042c6b94a47ba8318a53b819f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception raised in Job[29]: AttributeError('StringIO' object has no attribute 'statements')\n",
      "Exception raised in Job[34]: LLMDidNotFinishException(The LLM generation was not completed. Please increase try increasing the max_tokens and try again.)\n",
      "Exception raised in Job[11]: TimeoutError()\n",
      "Exception raised in Job[17]: TimeoutError()\n",
      "Exception raised in Job[41]: TimeoutError()\n",
      "Exception raised in Job[89]: TimeoutError()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.9815, 'faithfulness': 0.7227, 'factual_correctness': 0.4306, 'answer_relevancy': 0.9099, 'context_entity_recall': 0.5417, 'noise_sensitivity_relevant': 0.2547}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_retrieval_result = evaluate(\n",
    "    dataset=EvaluationDataset.from_pandas(ensemble_retrieval_dataset),\n",
    "    metrics=[\n",
    "        LLMContextRecall(),\n",
    "        Faithfulness(),\n",
    "        FactualCorrectness(),\n",
    "        ResponseRelevancy(),\n",
    "        ContextEntityRecall(),\n",
    "        NoiseSensitivity(),\n",
    "    ],\n",
    "    llm=evaluator_llm,\n",
    "    run_config=RunConfig(timeout=360),\n",
    ")\n",
    "ensemble_retrieval_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf610ed9",
   "metadata": {},
   "source": [
    "# Result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1590d952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             context_recall  faithfulness  factual_correctness  \\\n",
      "Method                                                           \n",
      "Naive                0.8889        0.8564                  NaN   \n",
      "BM25                 0.6296        0.6716               0.4572   \n",
      "Multi-Query          1.0000        0.8607               0.4522   \n",
      "Ensemble             0.9815        0.7227               0.4306   \n",
      "\n",
      "             answer_relevancy  context_entity_recall  \n",
      "Method                                                \n",
      "Naive                  0.9127                 0.5356  \n",
      "BM25                   0.7520                 0.4301  \n",
      "Multi-Query            0.9662                 0.4989  \n",
      "Ensemble               0.9099                    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Helper function to convert EvaluationResult to dict if needed\n",
    "def eval_result_to_dict(result):\n",
    "    # If already a dict, return as is\n",
    "    if isinstance(result, dict):\n",
    "        return result\n",
    "    # Try to use .dict() or .to_dict() if available\n",
    "    if hasattr(result, \"dict\"):\n",
    "        return result.dict()\n",
    "    if hasattr(result, \"to_dict\"):\n",
    "        return result.to_dict()\n",
    "    # Otherwise, try to use __dict__ (may include extra keys)\n",
    "    if hasattr(result, \"__dict__\"):\n",
    "        return dict(result.__dict__)\n",
    "    # If all else fails, raise error\n",
    "    raise TypeError(f\"Cannot convert {type(result)} to dict\")\n",
    "\n",
    "# Collect results into a list of tuples: (method, scores)\n",
    "results = [\n",
    "    (\"Naive\", eval_result_to_dict(naive_retrieval_result)),\n",
    "    (\"BM25\", eval_result_to_dict(bm25_retrieval_result)),\n",
    "    (\"Multi-Query\", eval_result_to_dict(multi_query_retrieval_result)),\n",
    "    (\"Ensemble\", eval_result_to_dict(ensemble_retrieval_result)),\n",
    "]\n",
    "\n",
    "# Extract the metrics from the 'scores' field of each result\n",
    "# Each 'scores' is typically a list of dicts (one per example); we want the mean for each metric\n",
    "import numpy as np\n",
    "\n",
    "metrics = [\n",
    "    \"context_recall\",\n",
    "    \"faithfulness\",\n",
    "    \"factual_correctness\",\n",
    "    \"answer_relevancy\",\n",
    "    \"context_entity_recall\"\n",
    "]\n",
    "\n",
    "table = {}\n",
    "for method, result in results:\n",
    "    # result['scores'] is a list of dicts, one per example\n",
    "    scores = result.get(\"scores\", [])\n",
    "    # Defensive: skip if scores is empty\n",
    "    if not scores:\n",
    "        table[method] = {metric: None for metric in metrics}\n",
    "        continue\n",
    "    # Each score is a dict with the metrics\n",
    "    # Compute mean for each metric\n",
    "    metric_means = {}\n",
    "    for metric in metrics:\n",
    "        values = [score.get(metric) for score in scores if metric in score]\n",
    "        # Only compute mean if there are values\n",
    "        if values:\n",
    "            metric_means[metric] = np.mean(values)\n",
    "        else:\n",
    "            metric_means[metric] = None\n",
    "    table[method] = metric_means\n",
    "\n",
    "# Create DataFrame: rows=methods, columns=metrics\n",
    "metrics_df = pd.DataFrame.from_dict(table, orient=\"index\")\n",
    "metrics_df.index.name = \"Method\"\n",
    "print(metrics_df.round(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
